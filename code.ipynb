{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tridibraj/brain-tumer-detection-cnn-model-94?scriptVersionId=188828736\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Dataset class for loading brain tumor data","metadata":{}},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n        self.image_paths = []\n        self.labels = []\n        \n        for label, class_name in enumerate(self.classes):\n            class_dir = os.path.join(root_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                self.image_paths.append(img_path)\n                self.labels.append(label)\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset instances","metadata":{}},{"cell_type":"code","source":"train_dataset = BrainTumorDataset(root_dir='/kaggle/input/brain-tumor-mri-dataset/Training', transform=train_transform)\ntest_dataset = BrainTumorDataset(root_dir='/kaggle/input/brain-tumor-mri-dataset/Testing', transform=test_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataloaders & define the CNN model","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 4)  # 4 classes\n    \n    def forward(self, x):\n        x = self.pool(nn.functional.relu(self.conv1(x)))\n        x = self.pool(nn.functional.relu(self.conv2(x)))\n        x = self.pool(nn.functional.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 28 * 28)  # Flatten\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torchviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchviz import make_dot\nfrom IPython.display import Image\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 4)  # 4 classes\n    \n    def forward(self, x):\n        x = self.pool(nn.functional.relu(self.conv1(x)))\n        x = self.pool(nn.functional.relu(self.conv2(x)))\n        x = self.pool(nn.functional.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 28 * 28)  # Flatten\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = CNNModel()\nx = torch.randn(1, 3, 224, 224)  # Dummy input\ny = model(x)\ndot = make_dot(y, params=dict(model.named_parameters()))\ndot.format = 'png'\ndot.render('cnn_model')\nImage('cnn_model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\nimport torch\nimport torch.nn as nn\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 4)  # 4 classes\n\n    def forward(self, x):\n        x = self.pool(nn.functional.relu(self.conv1(x)))\n        x = self.pool(nn.functional.relu(self.conv2(x)))\n        x = self.pool(nn.functional.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 28 * 28)  # Flatten\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = CNNModel()\nsummary(model, input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNNModel().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model save location\n","metadata":{}},{"cell_type":"code","source":"save_path = '/kaggle/working/trained_model.pth'\n\n# Ensure the directory exists before saving\nos.makedirs(os.path.dirname(save_path), exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training Function\n","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=10, save_path='trained_model.pth'):\n    model.train()\n    best_accuracy = 0.0  # Track best accuracy to save the best model\n    \n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            \n            # Calculate accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        epoch_loss = running_loss / len(train_dataset)\n        epoch_accuracy = correct / total\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n        \n        # Save the model if it has the best accuracy\n        if epoch_accuracy > best_accuracy:\n            best_accuracy = epoch_accuracy\n            torch.save(model.state_dict(), save_path)\n    \n    print(f\"Training complete. Best accuracy: {best_accuracy:.4f}. Model saved to {save_path}\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model testing Function\n","metadata":{}},{"cell_type":"code","source":"def test_model(model):\n    model.eval()\n    correct = 0\n    total = 0\n    predictions = []\n    true_labels = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            predictions.extend(predicted.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n    \n    accuracy = correct / total\n    print(f\"Accuracy on test set: {accuracy:.4f}\")\n    \n    return true_labels, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\n\n# Train the model and save it to /kaggle/working/\ntrain_model(model, criterion, optimizer, num_epochs=5, save_path=save_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ntrue_labels, predictions = test_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance evaluation","metadata":{}},{"cell_type":"code","source":"print(\"Classification Report:\")\nprint(classification_report(true_labels, predictions, target_names=['glioma', 'meningioma', 'notumor', 'pituitary']))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Generate the confusion matrix\ncm = confusion_matrix(true_labels, predictions)\n\n# Plotting the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=['glioma', 'meningioma', 'notumor', 'pituitary'], yticklabels=['glioma', 'meningioma', 'notumor', 'pituitary'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\n\nprecision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\nprint(f\"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n\nprecision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\nprint(f\"Macro-averaged Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model and save it to /kaggle/working/\ntrain_model(model, criterion, optimizer, num_epochs=10, save_path=save_path)\n\n# Ensure you unpack two values from test_model\ntrue_labels, predictions = test_model(model)\n\nprint(\"Classification Report:\")\nprint(classification_report(true_labels, predictions, target_names=['glioma', 'meningioma', 'notumor', 'pituitary']))\n\n# Generate the confusion matrix\ncm = confusion_matrix(true_labels, predictions)\n\n# Plotting the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=['glioma', 'meningioma', 'notumor', 'pituitary'], yticklabels=['glioma', 'meningioma', 'notumor', 'pituitary'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n\n# Calculate precision, recall, f1-score\nfrom sklearn.metrics import precision_recall_fscore_support\n\nprecision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\nprint(f\"Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n\nprecision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\nprint(f\"Macro-averaged Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport numpy as np\nimport os\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define transforms for the testing dataset\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Custom Dataset class for loading brain tumor data\nclass BrainTumorDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n        self.image_paths = []\n        self.labels = []\n        \n        for label, class_name in enumerate(self.classes):\n            class_dir = os.path.join(root_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                self.image_paths.append(img_path)\n                self.labels.append(label)\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n# Load the model state dictionary\nmodel_path = '/kaggle/working/trained_model.pth'\nstate_dict = torch.load(model_path, map_location=device)\n\n# Define your model architecture\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 4)  # 4 classes\n    \n    def forward(self, x):\n        x = self.pool(nn.functional.relu(self.conv1(x)))\n        x = self.pool(nn.functional.relu(self.conv2(x)))\n        x = self.pool(nn.functional.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 28 * 28)  # Flatten\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Instantiate your model\nmodel = CNNModel().to(device)\n\n# Load state_dict into your model\nmodel.load_state_dict(state_dict)\nmodel.eval()  # Set the model to evaluation mode\n\n# Create dataset instance for testing\ntest_dataset = BrainTumorDataset(root_dir='/kaggle/input/brain-tumor-mri-dataset/Testing', transform=test_transform)\n\n# Randomly select 10 images from the test set\nnum_images = 20\nrandom_indices = np.random.choice(len(test_dataset), num_images, replace=False)\n\nprint(\"Actual Label | Predicted Label\")\nprint(\"-----------------------------\")\n\n# Perform inference on each selected image\nfor idx in random_indices:\n    image, label = test_dataset[idx]\n    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n    with torch.no_grad():\n        output = model(image)\n        _, predicted = torch.max(output.data, 1)\n    \n    actual_label = test_dataset.classes[label]\n    predicted_label = test_dataset.classes[predicted.item()]\n    \n    print(f\"{actual_label:12} | {predicted_label:14}\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}